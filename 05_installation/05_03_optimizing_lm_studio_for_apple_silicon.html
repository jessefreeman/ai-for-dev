
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <title>Optimizing LM Studio for Apple Silicon Â· HonKit</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="HonKit 5.1.4">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/@honkit/honkit-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="05_04_picking_models_in_lm_studio.html" />
    
    
    <link rel="prev" href="05_02_configuring_lm_studio_on_apple_silicon.html" />
    

    </head>
    <body>
        
<div class="book honkit-cloak">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" >
            
                <span>
            
                    
                    Introduction
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="../01_introduction/01_01_how_to_use_this_guide.html">
            
                <a href="../01_introduction/01_01_how_to_use_this_guide.html">
            
                    
                    How To Use This Guide
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="../01_introduction/01_02_why_run_models_locally.html">
            
                <a href="../01_introduction/01_02_why_run_models_locally.html">
            
                    
                    Why Run Large Language Models Locally?
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" >
            
                <span>
            
                    
                    Understanding Large Language Models
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="../02_understanding_large_language_models/02_01_overview_of_llms.html">
            
                <a href="../02_understanding_large_language_models/02_01_overview_of_llms.html">
            
                    
                    Overview of Large Language Models (LLMs)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="../02_understanding_large_language_models/02_02_model_variations.html">
            
                <a href="../02_understanding_large_language_models/02_02_model_variations.html">
            
                    
                    Models Variations
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="../02_understanding_large_language_models/02_03_model_naming_conventions.html">
            
                <a href="../02_understanding_large_language_models/02_03_model_naming_conventions.html">
            
                    
                    Model Naming Conventions
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="../02_understanding_large_language_models/02_04_parameter_size.html">
            
                <a href="../02_understanding_large_language_models/02_04_parameter_size.html">
            
                    
                    Parameter Size
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="../02_understanding_large_language_models/02_05_quantization.html">
            
                <a href="../02_understanding_large_language_models/02_05_quantization.html">
            
                    
                    Quantization
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.6" data-path="../02_understanding_large_language_models/02_06_quantization_schemes.html">
            
                <a href="../02_understanding_large_language_models/02_06_quantization_schemes.html">
            
                    
                    Quantization Schemes
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.7" data-path="../02_understanding_large_language_models/02_07_scaling_models.html">
            
                <a href="../02_understanding_large_language_models/02_07_scaling_models.html">
            
                    
                    How Models Are Scaled
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" >
            
                <span>
            
                    
                    Selecting Models
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="../03_selecting_models/03_01_selecting_the right model.html">
            
                <a href="../03_selecting_models/03_01_selecting_the right model.html">
            
                    
                    Selecting the Right Model
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="../03_selecting_models/03_02_pick_the_right_model_for_your_memory.html">
            
                <a href="../03_selecting_models/03_02_pick_the_right_model_for_your_memory.html">
            
                    
                    Pick the Right Model for Your Memory
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3" data-path="../03_selecting_models/03_03_model_size_and_memory.html">
            
                <a href="../03_selecting_models/03_03_model_size_and_memory.html">
            
                    
                    Model Size and Memory
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.4" data-path="../03_selecting_models/03_04_cpu_vs_gpu_inferencing.html">
            
                <a href="../03_selecting_models/03_04_cpu_vs_gpu_inferencing.html">
            
                    
                    CPU vs. GPU and Inferencing
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5" data-path="../03_selecting_models/03_05_offloading_to_the_gpu.html">
            
                <a href="../03_selecting_models/03_05_offloading_to_the_gpu.html">
            
                    
                    Offloading to the GPU
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.6" data-path="../03_selecting_models/03_06_picking_code_llama_instruct_variations.html">
            
                <a href="../03_selecting_models/03_06_picking_code_llama_instruct_variations.html">
            
                    
                    CodeLlama 3.1 Instruct Variations
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" >
            
                <span>
            
                    
                    Models For Coding
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../04_models_for_ coding/04_01_overview_of_code_llama_variations.html">
            
                <a href="../04_models_for_ coding/04_01_overview_of_code_llama_variations.html">
            
                    
                    Overview of Code Llama Variations
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2" data-path="../04_models_for_ coding/04_02_other_open_source_coding_models.html">
            
                <a href="../04_models_for_ coding/04_02_other_open_source_coding_models.html">
            
                    
                    Other Notable Open Source Models for Coding
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" >
            
                <span>
            
                    
                    Installation
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1" data-path="05_01_installing_lm_studio.html">
            
                <a href="05_01_installing_lm_studio.html">
            
                    
                    Installing LM Studio
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2" data-path="05_02_configuring_lm_studio_on_apple_silicon.html">
            
                <a href="05_02_configuring_lm_studio_on_apple_silicon.html">
            
                    
                    Configuring LM Studio on Apple Silicon
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.6.3" data-path="05_03_optimizing_lm_studio_for_apple_silicon.html">
            
                <a href="05_03_optimizing_lm_studio_for_apple_silicon.html">
            
                    
                    Optimizing LM Studio for Apple Silicon
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4" data-path="05_04_picking_models_in_lm_studio.html">
            
                <a href="05_04_picking_models_in_lm_studio.html">
            
                    
                    Picking Models in LM Studio
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.7" >
            
                <span>
            
                    
                    Evaluation
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.7.1" data-path="../06_evaluation/06_01_testing_each_model.html">
            
                <a href="../06_evaluation/06_01_testing_each_model.html">
            
                    
                    Testing Each Model
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.2" data-path="../06_evaluation/06_02_evaluating_models.html">
            
                <a href="../06_evaluation/06_02_evaluating_models.html">
            
                    
                    Evaluating Models with a Standardized Test
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.8" >
            
                <span>
            
                    
                    Best Practices
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.8.1" data-path="../07_best_practices/07_01_best_practices_for_running_local_llms.html">
            
                <a href="../07_best_practices/07_01_best_practices_for_running_local_llms.html">
            
                    
                    Best Practices for Running Local LLMs
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.9" >
            
                <span>
            
                    
                    Prompts
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.9.1" data-path="../08_prompts/08_01_collection_of_prompts.html">
            
                <a href="../08_prompts/08_01_collection_of_prompts.html">
            
                    
                    Collection of Prompts
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.2" data-path="../08_prompts/08_02_example_create_shell_script.html">
            
                <a href="../08_prompts/08_02_example_create_shell_script.html">
            
                    
                    Creating a Shell Script
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.10" >
            
                <span>
            
                    
                    Advanced Usage
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.10.1" data-path="../09_advanced_usage/09_01_advanced_model_tuning.html">
            
                <a href="../09_advanced_usage/09_01_advanced_model_tuning.html">
            
                    
                    Advanced Model Tuning
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.2" data-path="../09_advanced_usage/09_02_integrating_llms_into_workflows.html">
            
                <a href="../09_advanced_usage/09_02_integrating_llms_into_workflows.html">
            
                    
                    Integrating LLMs into Workflows
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.3" data-path="../09_advanced_usage/09_03_custom_built_pcs.html">
            
                <a href="../09_advanced_usage/09_03_custom_built_pcs.html">
            
                    
                    Custom Built PCs
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.11" >
            
                <span>
            
                    
                    Benchmarks
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.11.1" data-path="../10_benchmarks/10_01_geekbench_ai_benchmark.html">
            
                <a href="../10_benchmarks/10_01_geekbench_ai_benchmark.html">
            
                    
                    Personal Computer Results
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.2" data-path="../10_benchmarks/10_02_ryzen_7_5800_32.html">
            
                <a href="../10_benchmarks/10_02_ryzen_7_5800_32.html">
            
                    
                    Ryzen 7 5800X + RTX 4070 Super Performance Overview
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.3" data-path="../10_benchmarks/10_03_m3_max.html">
            
                <a href="../10_benchmarks/10_03_m3_max.html">
            
                    
                    MacBook Pro M3 Max Performance Overview
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.4" data-path="../10_benchmarks/10_04_nuc9v7qnx.html">
            
                <a href="../10_benchmarks/10_04_nuc9v7qnx.html">
            
                    
                    Intel NUC9V7QNX Performance Overview
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.12" >
            
                <span>
            
                    
                    Additional Resources
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.12.1" data-path="../11_additional_resources/11_01_tools.html">
            
                <a href="../11_additional_resources/11_01_tools.html">
            
                    
                    Tools
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.2" data-path="../11_additional_resources/11_02_articles.html">
            
                <a href="../11_additional_resources/11_02_articles.html">
            
                    
                    Articles
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.3" data-path="../11_additional_resources/11_03_in_the_news.html">
            
                <a href="../11_additional_resources/11_03_in_the_news.html">
            
                    
                    In the News
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://github.com/honkit/honkit" target="blank" class="gitbook-link">
            Published with HonKit
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Optimizing LM Studio for Apple Silicon</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="optimizing-lm-studio-for-apple-silicon">Optimizing LM Studio for Apple Silicon</h1>
<p>Running large language models (LLMs) locally on your Apple Silicon Mac can significantly enhance performance, privacy, and cost efficiency. However, to get the best results, it is crucial to configure LM Studio appropriately based on your specific hardware capabilities. Hereâs a detailed guide on the key settings and their importance, followed by tailored configurations for high-end, medium-end, and low-end Apple Silicon Macs.</p>
<p>Key Settings and Their Importance</p>
<p><strong>Context Length (n_ctx)</strong>: The context length determines how much text the model can consider at once. Setting an appropriate context length is essential for balancing memory usage and processing speed. A shorter context length reduces memory consumption and speeds up processing but may limit the modelâs understanding of the context. For high-end systems, a longer context length can be afforded, providing more comprehensive context analysis.</p>
<p><strong>Tokens to Generate (n_predict):</strong> This setting controls the number of tokens (words or parts of words) the model generates in response to a prompt. Limiting the number of tokens helps prevent excessively long responses, speeding up the generation process. Itâs crucial to find a balance that allows the model to provide useful outputs without overloading the system.</p>
<p><strong>CPU Threads (n_threads):</strong> Configuring the number of CPU threads used by LM Studio is vital for efficient processing. Utilizing more CPU threads can speed up computation by leveraging the multi-core capabilities of modern CPUs. However, itâs important to match the number of threads to the physical cores available to avoid diminishing returns or potential system instability.</p>
<p><strong>GPU Offload (n_gpu_layers):</strong> The GPU offload setting determines how many layers of the modelâs computation are handled by the GPU. Offloading computation to the GPU can significantly reduce the load on the CPU and speed up processing, especially for larger models. The number of layers to offload should be adjusted based on the GPUâs capabilities and the overall system memory.</p>
<p><strong>Memory Allocation:</strong> Ensuring that sufficient memory is allocated to LM Studio is essential for handling larger models and datasets efficiently. Optimizing memory allocation helps prevent system slowdowns and ensures that the model runs smoothly without consuming excessive resources.</p>
<h2 id="optimized-configurations-for-apple-silicon-macs">Optimized Configurations for Apple Silicon Macs</h2>
<p>Here are the recommended configurations for three types of Apple Silicon Macs: a high-end system (MacBook Pro M3 Max with 32GB RAM), a medium-end system (MacBook Pro M1 Pro with 16GB RAM), and a low-end system (MacBook Air M1 with 8GB RAM).</p>
<p>Apple Silicon Cheat Sheet</p>
<p><strong>High-End System: MacBook Pro M3 Max with 32GB RAM</strong></p>
<p>For high-end systems like the MacBook Pro M3 Max with 32GB RAM, maximizing the context length and offloading significant computation to the GPU will leverage the full potential of the hardware. The settings should be adjusted as follows:</p>
<table>
<thead>
<tr>
<th>Configuration Option</th>
<th>Setting</th>
<th>Impact</th>
</tr>
</thead>
<tbody>
<tr>
<td>Context Length (n_ctx)</td>
<td>2048</td>
<td>Reduces memory usage and speeds up processing without significantly impacting context understanding.</td>
</tr>
<tr>
<td>Tokens to Generate (n_predict)</td>
<td>100</td>
<td>Limits the response length, speeding up response time.</td>
</tr>
<tr>
<td>CPU Threads (n_threads)</td>
<td>8 (or number of physical cores)</td>
<td>Utilizes more CPU cores, speeding up processing.</td>
</tr>
<tr>
<td>GPU Offload (n_gpu_layers)</td>
<td>24</td>
<td>Shifts more computation to the GPU, reducing CPU load.</td>
</tr>
<tr>
<td>Memory Allocation</td>
<td>Maximize available RAM</td>
<td>Ensures sufficient memory is allocated to LM Studio, preventing slowdowns.</td>
</tr>
</tbody>
</table>
<hr></hr>
<h4 id="medium-end-system-macbook-pro-m1-pro-with-16gb-ram"><strong>Medium-End System: MacBook Pro M1 Pro with 16GB RAM</strong></h4>
<p>For medium-end systems like the MacBook Pro M1 Pro with 16GB RAM, a balanced approach is necessary. Adjusting the context length and GPU offload settings will help maintain performance without overloading the system:</p>
<table>
<thead>
<tr>
<th>Configuration Option</th>
<th>Setting</th>
<th>Impact</th>
</tr>
</thead>
<tbody>
<tr>
<td>Context Length (n_ctx)</td>
<td>1024</td>
<td>Balances memory usage and processing speed, providing adequate context analysis.</td>
</tr>
<tr>
<td>Tokens to Generate (n_predict)</td>
<td>100</td>
<td>Limits the response length, speeding up response time.</td>
</tr>
<tr>
<td>CPU Threads (n_threads)</td>
<td>8 (or number of physical cores)</td>
<td>Utilizes more CPU cores, speeding up processing.</td>
</tr>
<tr>
<td>GPU Offload (n_gpu_layers)</td>
<td>16</td>
<td>Distributes some computation to the GPU, reducing CPU load.</td>
</tr>
<tr>
<td>Memory Allocation</td>
<td>Optimize for 16GB</td>
<td>Ensures efficient memory usage without overloading the system.</td>
</tr>
</tbody>
</table>
<hr></hr>
<h4 id="low-end-system-macbook-air-m1-with-8gb-ram"><strong>Low-End System: MacBook Air M1 with 8GB RAM</strong></h4>
<p>For low-end systems like the MacBook Air M1 with 8GB RAM, it's essential to reduce the load on both the CPU and GPU. Shortening the context length and limiting the number of tokens generated will help maintain performance:</p>
<table>
<thead>
<tr>
<th>Configuration Option</th>
<th>Setting</th>
<th>Impact</th>
</tr>
</thead>
<tbody>
<tr>
<td>Context Length (n_ctx)</td>
<td>512</td>
<td>Reduces memory usage and processing load, while still providing sufficient context.</td>
</tr>
<tr>
<td>Tokens to Generate (n_predict)</td>
<td>50</td>
<td>Limits the response length, speeding up response time and reducing resource usage.</td>
</tr>
<tr>
<td>CPU Threads (n_threads)</td>
<td>4 (or number of physical cores)</td>
<td>Utilizes available CPU cores efficiently without overloading the system.</td>
</tr>
<tr>
<td>GPU Offload (n_gpu_layers)</td>
<td>8</td>
<td>Shifts some computation to the GPU, alleviating CPU load.</td>
</tr>
<tr>
<td>Memory Allocation</td>
<td>Optimize for 8GB</td>
<td>Ensures efficient memory usage without overloading the system.</td>
</tr>
</tbody>
</table>
<p>By following these configuration settings tailored to your specific Apple Silicon Mac, you can ensure optimal performance when running large language models in LM Studio. Each table provides a balance between resource allocation and processing efficiency to make the most out of your hardware capabilities, from high-end systems with abundant resources to lower-end systems with more constrained hardware.</p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="05_02_configuring_lm_studio_on_apple_silicon.html" class="navigation navigation-prev " aria-label="Previous page: Configuring LM Studio on Apple Silicon">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="05_04_picking_models_in_lm_studio.html" class="navigation navigation-next " aria-label="Next page: Picking Models in LM Studio">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Optimizing LM Studio for Apple Silicon","level":"1.6.3","depth":2,"next":{"title":"Picking Models in LM Studio","level":"1.6.4","depth":2,"path":"05_installation/05_04_picking_models_in_lm_studio.md","ref":"./05_installation/05_04_picking_models_in_lm_studio.md","articles":[]},"previous":{"title":"Configuring LM Studio on Apple Silicon","level":"1.6.2","depth":2,"path":"05_installation/05_02_configuring_lm_studio_on_apple_silicon.md","ref":"./05_installation/05_02_configuring_lm_studio_on_apple_silicon.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":[],"pluginsConfig":{"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56},"embedFonts":false},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"05_installation/05_03_optimizing_lm_studio_for_apple_silicon.md","mtime":"2024-08-27T18:31:41.767Z","type":"markdown"},"gitbook":{"version":"5.1.4","time":"2024-08-27T18:50:45.127Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <noscript>
        <style>
            .honkit-cloak {
                display: block !important;
            }
        </style>
    </noscript>
    <script>
        // Restore sidebar state as critical path for prevent layout shift
        function __init__getSidebarState(defaultValue){
            var baseKey = "";
            var key = baseKey + ":sidebar";
            try {
                var value = localStorage[key];
                if (value === undefined) {
                    return defaultValue;
                }
                var parsed = JSON.parse(value);
                return parsed == null ? defaultValue : parsed;
            } catch (e) {
                return defaultValue;
            }
        }
        function __init__restoreLastSidebarState() {
            var isMobile = window.matchMedia("(max-width: 600px)").matches;
            if (isMobile) {
                // Init last state if not mobile
                return;
            }
            var sidebarState = __init__getSidebarState(true);
            var book = document.querySelector(".book");
            // Show sidebar if it enabled
            if (sidebarState && book) {
                book.classList.add("without-animation", "with-summary");
            }
        }

        try {
            __init__restoreLastSidebarState();
        } finally {
            var book = document.querySelector(".book");
            book.classList.remove("honkit-cloak");
        }
    </script>
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

