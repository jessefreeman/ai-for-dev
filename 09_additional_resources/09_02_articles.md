# Articles

This section lists recommended reading and community links.



### Model Selection

* [50 Open-Source Options for Running LLMs Locally](https://medium.com/thedeephub/50-open-source-options-for-running-llms-locally-db1ec6f5a54f) by [Vince Lam](https://medium.com/@vince-lam): An extensive list of 50 open-source tools and projects for running LLMs locally, offering various options and their use cases.

### Installation and Configuration

* [Mac for Large Language Models](https://www.hardware-corner.net/guides/mac-for-large-language-models/) by [Allan Witt](https://www.hardware-corner.net/): A comprehensive guide on configuring Macs, especially with Apple Silicon, for running large language models efficiently.
* [Local LLMs on Apple Silicon](https://medium.com/@aadityaubhat/local-llms-on-apple-silicon-39194de71ab7) by [Aaditya Bhat](https://medium.com/@aadityaubhat): Insights and techniques for running local LLMs \`on Apple Silicon, highlighting performance optimizations and practical applications.
* [Local LLM Fine-Tuning on Mac M1 16GB](https://towardsdatascience.com/local-llm-fine-tuning-on-mac-m1-16gb-f59f4f598be7) by [Shaw Talebi](https://shawhin.medium.com/): This article explores fine-tuning local LLMs on a Mac M1 with 16GB RAM, offering insights and steps for effective model training and optimization.
* [A Simple, Practical Guide to Running Large-Language Models on Your Laptop](https://medium.com/predict/a-simple-comprehensive-guide-to-running-large-language-models-locally-on-cpu-and-or-gpu-using-c0c2a8483eee) by [Ryan Stewart](https://medium.com/@ryanstewart): This guide shows how to run large-language models locally on your laptop using `llama-cpp-python` and GGUF models. It highlights benefits like cost savings, privacy, and faster iteration, providing step-by-step instructions for setup on both CPU and GPU.

### Advanced Usage

* [Using a Local LLM as a Free Coding Copilot in VS Code](https://medium.com/@smfraser/how-to-use-a-local-llm-as-a-free-coding-copilot-in-vs-code-6dffc053369d) by [Simon Fraser](https://medium.com/@smfraser): A guide on setting up and using a local LLM as a coding assistant in VS Code, detailing the setup process and benefits.
* [Integrating Large Language Models with Apple's Core ML](https://huggingface.co/blog/swift-coreml-llm) by [Pedro Cuenca](https://huggingface.co/pcuenq): This article discusses the integration of large language models with Apple's Core ML, providing a detailed guide on leveraging these models in Swift applications.

### Local Servers

- [How to Set Up and Use a Windows NAS](https://www.xda-developers.com/how-to-set-up-and-use-windows-nas/): This article guides you through setting up a Windows NAS, covering hardware selection, drive configuration, and network sharing. It also includes tips for optimizing performance and securing your NAS for a home or small office network.
