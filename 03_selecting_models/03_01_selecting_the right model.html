
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <title>Selecting the Right Model · HonKit</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="HonKit 5.1.4">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/@honkit/honkit-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="03_02_pick_the_right_model_for_your_memory.html" />
    
    

    </head>
    <body>
        
<div class="book honkit-cloak">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" >
            
                <span>
            
                    
                    Introduction
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="../01_introduction/01_01_how_to_use_this_guide.html">
            
                <a href="../01_introduction/01_01_how_to_use_this_guide.html">
            
                    
                    How To Use This Guide
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="../01_introduction/01_02_why_run_models_locally.html">
            
                <a href="../01_introduction/01_02_why_run_models_locally.html">
            
                    
                    Why Run Large Language Models Locally?
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" >
            
                <span>
            
                    
                    Understanding Large Language Models
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="../02_understanding_large_language_models/02_01_overview_of_llms.html">
            
                <a href="../02_understanding_large_language_models/02_01_overview_of_llms.html">
            
                    
                    Overview of Large Language Models (LLMs)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="../02_understanding_large_language_models/02_02_model_variations.html">
            
                <a href="../02_understanding_large_language_models/02_02_model_variations.html">
            
                    
                    Models Variations
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="../02_understanding_large_language_models/02_03_model_naming_conventions.html">
            
                <a href="../02_understanding_large_language_models/02_03_model_naming_conventions.html">
            
                    
                    Model Naming Conventions
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="../02_understanding_large_language_models/02_04_parameter_size.html">
            
                <a href="../02_understanding_large_language_models/02_04_parameter_size.html">
            
                    
                    Parameter Size
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="../02_understanding_large_language_models/02_05_quantization.html">
            
                <a href="../02_understanding_large_language_models/02_05_quantization.html">
            
                    
                    Quantization
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.6" data-path="../02_understanding_large_language_models/02_06_quantization_schemes.html">
            
                <a href="../02_understanding_large_language_models/02_06_quantization_schemes.html">
            
                    
                    Quantization Schemes
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.7" data-path="../02_understanding_large_language_models/02_07_scaling_models.html">
            
                <a href="../02_understanding_large_language_models/02_07_scaling_models.html">
            
                    
                    How Models Are Scaled
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" >
            
                <span>
            
                    
                    Selecting Models
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter active" data-level="1.4.1" data-path="03_01_selecting_the right model.html">
            
                <a href="03_01_selecting_the right model.html">
            
                    
                    Selecting the Right Model
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="03_02_pick_the_right_model_for_your_memory.html">
            
                <a href="03_02_pick_the_right_model_for_your_memory.html">
            
                    
                    Pick the Right Model for Your Memory
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3" data-path="03_03_model_size_and_memory.html">
            
                <a href="03_03_model_size_and_memory.html">
            
                    
                    Model Size and Memory
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.4" data-path="03_04_cpu_vs_gpu_inferencing.html">
            
                <a href="03_04_cpu_vs_gpu_inferencing.html">
            
                    
                    CPU vs. GPU and Inferencing
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5" data-path="03_05_offloading_to_the_gpu.html">
            
                <a href="03_05_offloading_to_the_gpu.html">
            
                    
                    Offloading to the GPU
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.6" data-path="03_06_picking_code_llama_instruct_variations.html">
            
                <a href="03_06_picking_code_llama_instruct_variations.html">
            
                    
                    CodeLlama 3.1 Instruct Variations
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" >
            
                <span>
            
                    
                    Models For Coding
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../04_models_for_ coding/04_01_overview_of_code_llama_variations.html">
            
                <a href="../04_models_for_ coding/04_01_overview_of_code_llama_variations.html">
            
                    
                    Overview of Code Llama Variations
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2" data-path="../04_models_for_ coding/04_02_other_open_source_coding_models.html">
            
                <a href="../04_models_for_ coding/04_02_other_open_source_coding_models.html">
            
                    
                    Other Notable Open Source Models for Coding
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" >
            
                <span>
            
                    
                    Installation
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1" data-path="../05_installation/05_01_installing_lm_studio.html">
            
                <a href="../05_installation/05_01_installing_lm_studio.html">
            
                    
                    Installing LM Studio
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2" data-path="../05_installation/05_02_configuring_lm_studio_on_apple_silicon.html">
            
                <a href="../05_installation/05_02_configuring_lm_studio_on_apple_silicon.html">
            
                    
                    Configuring LM Studio on Apple Silicon
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.3" data-path="../05_installation/05_03_optimizing_lm_studio_for_apple_silicon.html">
            
                <a href="../05_installation/05_03_optimizing_lm_studio_for_apple_silicon.html">
            
                    
                    Optimizing LM Studio for Apple Silicon
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4" data-path="../05_installation/05_04_picking_models_in_lm_studio.html">
            
                <a href="../05_installation/05_04_picking_models_in_lm_studio.html">
            
                    
                    Picking Models in LM Studio
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.7" >
            
                <span>
            
                    
                    Evaluation
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.7.1" data-path="../06_evaluation/06_01_testing_each_model.html">
            
                <a href="../06_evaluation/06_01_testing_each_model.html">
            
                    
                    Testing Each Model
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.2" data-path="../06_evaluation/06_02_evaluating_models.html">
            
                <a href="../06_evaluation/06_02_evaluating_models.html">
            
                    
                    Evaluating Models with a Standardized Test
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.8" >
            
                <span>
            
                    
                    Best Practices
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.8.1" data-path="../07_best_practices/07_01_best_practices_for_running_local_llms.html">
            
                <a href="../07_best_practices/07_01_best_practices_for_running_local_llms.html">
            
                    
                    Best Practices for Running Local LLMs
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.9" >
            
                <span>
            
                    
                    Prompts
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.9.1" data-path="../08_prompts/08_01_collection_of_prompts.html">
            
                <a href="../08_prompts/08_01_collection_of_prompts.html">
            
                    
                    Collection of Prompts
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.2" data-path="../08_prompts/08_02_example_create_shell_script.html">
            
                <a href="../08_prompts/08_02_example_create_shell_script.html">
            
                    
                    Creating a Shell Script
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.10" >
            
                <span>
            
                    
                    Advanced Usage
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.10.1" data-path="../09_advanced_usage/09_01_advanced_model_tuning.html">
            
                <a href="../09_advanced_usage/09_01_advanced_model_tuning.html">
            
                    
                    Advanced Model Tuning
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.2" data-path="../09_advanced_usage/09_02_integrating_llms_into_workflows.html">
            
                <a href="../09_advanced_usage/09_02_integrating_llms_into_workflows.html">
            
                    
                    Integrating LLMs into Workflows
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.3" data-path="../09_advanced_usage/09_03_custom_built_pcs.html">
            
                <a href="../09_advanced_usage/09_03_custom_built_pcs.html">
            
                    
                    Custom Built PCs
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.11" >
            
                <span>
            
                    
                    Benchmarks
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.11.1" data-path="../10_benchmarks/10_01_geekbench_ai_benchmark.html">
            
                <a href="../10_benchmarks/10_01_geekbench_ai_benchmark.html">
            
                    
                    Personal Computer Results
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.2" data-path="../10_benchmarks/10_02_ryzen_7_5800_32.html">
            
                <a href="../10_benchmarks/10_02_ryzen_7_5800_32.html">
            
                    
                    Ryzen 7 5800X + RTX 4070 Super Performance Overview
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.3" data-path="../10_benchmarks/10_03_m3_max.html">
            
                <a href="../10_benchmarks/10_03_m3_max.html">
            
                    
                    MacBook Pro M3 Max Performance Overview
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.4" data-path="../10_benchmarks/10_04_nuc9v7qnx.html">
            
                <a href="../10_benchmarks/10_04_nuc9v7qnx.html">
            
                    
                    Intel NUC9V7QNX Performance Overview
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.12" >
            
                <span>
            
                    
                    Additional Resources
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.12.1" data-path="../11_additional_resources/11_01_tools.html">
            
                <a href="../11_additional_resources/11_01_tools.html">
            
                    
                    Tools
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.2" data-path="../11_additional_resources/11_02_articles.html">
            
                <a href="../11_additional_resources/11_02_articles.html">
            
                    
                    Articles
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.3" data-path="../11_additional_resources/11_03_in_the_news.html">
            
                <a href="../11_additional_resources/11_03_in_the_news.html">
            
                    
                    In the News
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://github.com/honkit/honkit" target="blank" class="gitbook-link">
            Published with HonKit
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Selecting the Right Model</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="selecting-the-right-model">Selecting the Right Model</h1>
<p>After understanding the benefits of running large language models (LLMs) locally, the next step is to effectively select and use the right model for your needs. These are the 4 steps you’ll need to do in inorder to add local LLM models into your workflow, ensuring you make the most of your hardware and achieve the best performance possible.</p>
<p><strong>Step 1: Understand Your Computer’s Capabilities</strong></p>
<p>The first step is to assess your computer's capabilities. The feasibility and performance of running models locally depend heavily on your hardware specifications, such as RAM, GPU, CPU, and storage. A system with 32GB of RAM and a powerful GPU, for instance, will handle more demanding models and deliver faster, more efficient performance than a less equipped setup. Understanding your hardware's strengths and limitations will guide you in choosing a model that fits your system’s capabilities.</p>
<p><strong>Step 2: Select the Right Model</strong></p>
<p>Once you understand your hardware, the next step is to select the appropriate model. These models come in various configurations that balance memory usage, computational resources, and speed. Your choice should be based on your specific needs—whether you need quick, iterative code completion, detailed instruction-based coding, or the ability to handle complex, resource-intensive tasks. Familiarizing yourself with the different model variations and their strengths will help you choose the most suitable option.</p>
<p><strong>Step 3: Decode the Naming Structure</strong></p>
<p>The naming structure of each model provides valuable insights into their configurations. For example, in the model name <strong>CodeLlama-13b-Instruct.Q3_K_M.gguf</strong>, each part denotes key attributes such as the model family, parameter size, variant type, quantization level, and optimization format. Understanding this structured naming helps you quickly identify a model’s capabilities and compatibility with your system specifications, making the selection process more straightforward.</p>
<p><strong>Step 4: Test the Model</strong></p>
<p>Before fully integrating a selected model into your workflow, it’s crucial to test it. Running standardized tests allows you to evaluate the model's response time, accuracy, and resource usage. This step ensures that the model meets your performance expectations and aligns well with your hardware capabilities. Testing helps you identify any potential issues and make necessary adjustments before deploying the model for regular use.</p>
<p>By following these four steps—understanding your computer's capabilities, selecting the right model, decoding the naming structure, and performing thorough testing—you can effectively integrate local LLMs into your development workflow. This structured approach enhances your coding efficiency and leverages the full potential of advanced AI models, ensuring you get the best possible performance from your setup.</p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                
                <a href="03_02_pick_the_right_model_for_your_memory.html" class="navigation navigation-next navigation-unique" aria-label="Next page: Pick the Right Model for Your Memory">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Selecting the Right Model","level":"1.4.1","depth":2,"next":{"title":"Pick the Right Model for Your Memory","level":"1.4.2","depth":2,"path":"03_selecting_models/03_02_pick_the_right_model_for_your_memory.md","ref":"./03_selecting_models/03_02_pick_the_right_model_for_your_memory.md","articles":[]},"previous":{"title":"Selecting Models","level":"1.4","depth":1,"ref":"","articles":[{"title":"Selecting the Right Model","level":"1.4.1","depth":2,"path":"03_selecting_models/03_01_selecting_the right model.md","ref":"./03_selecting_models/03_01_selecting_the right model.md","articles":[]},{"title":"Pick the Right Model for Your Memory","level":"1.4.2","depth":2,"path":"03_selecting_models/03_02_pick_the_right_model_for_your_memory.md","ref":"./03_selecting_models/03_02_pick_the_right_model_for_your_memory.md","articles":[]},{"title":"Model Size and Memory","level":"1.4.3","depth":2,"path":"03_selecting_models/03_03_model_size_and_memory.md","ref":"./03_selecting_models/03_03_model_size_and_memory.md","articles":[]},{"title":"CPU vs. GPU and Inferencing","level":"1.4.4","depth":2,"path":"03_selecting_models/03_04_cpu_vs_gpu_inferencing.md","ref":"./03_selecting_models/03_04_cpu_vs_gpu_inferencing.md","articles":[]},{"title":"Offloading to the GPU","level":"1.4.5","depth":2,"path":"03_selecting_models/03_05_offloading_to_the_gpu.md","ref":"./03_selecting_models/03_05_offloading_to_the_gpu.md","articles":[]},{"title":"CodeLlama 3.1 Instruct Variations","level":"1.4.6","depth":2,"path":"03_selecting_models/03_06_picking_code_llama_instruct_variations.md","ref":"./03_selecting_models/03_06_picking_code_llama_instruct_variations.md","articles":[]}]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":[],"pluginsConfig":{"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56},"embedFonts":false},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"03_selecting_models/03_01_selecting_the right model.md","mtime":"2024-08-27T18:31:41.762Z","type":"markdown"},"gitbook":{"version":"5.1.4","time":"2024-08-27T18:50:45.127Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <noscript>
        <style>
            .honkit-cloak {
                display: block !important;
            }
        </style>
    </noscript>
    <script>
        // Restore sidebar state as critical path for prevent layout shift
        function __init__getSidebarState(defaultValue){
            var baseKey = "";
            var key = baseKey + ":sidebar";
            try {
                var value = localStorage[key];
                if (value === undefined) {
                    return defaultValue;
                }
                var parsed = JSON.parse(value);
                return parsed == null ? defaultValue : parsed;
            } catch (e) {
                return defaultValue;
            }
        }
        function __init__restoreLastSidebarState() {
            var isMobile = window.matchMedia("(max-width: 600px)").matches;
            if (isMobile) {
                // Init last state if not mobile
                return;
            }
            var sidebarState = __init__getSidebarState(true);
            var book = document.querySelector(".book");
            // Show sidebar if it enabled
            if (sidebarState && book) {
                book.classList.add("without-animation", "with-summary");
            }
        }

        try {
            __init__restoreLastSidebarState();
        } finally {
            var book = document.querySelector(".book");
            book.classList.remove("honkit-cloak");
        }
    </script>
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

