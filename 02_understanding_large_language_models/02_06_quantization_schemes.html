
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <title>Quantization Schemes · HonKit</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="HonKit 5.1.4">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/@honkit/honkit-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="02_07_scaling_models.html" />
    
    
    <link rel="prev" href="02_05_quantization.html" />
    

    </head>
    <body>
        
<div class="book honkit-cloak">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" >
            
                <span>
            
                    
                    Introduction
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="../01_introduction/01_01_how_to_use_this_guide.html">
            
                <a href="../01_introduction/01_01_how_to_use_this_guide.html">
            
                    
                    How To Use This Guide
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="../01_introduction/01_02_why_run_models_locally.html">
            
                <a href="../01_introduction/01_02_why_run_models_locally.html">
            
                    
                    Why Run Large Language Models Locally?
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" >
            
                <span>
            
                    
                    Understanding Large Language Models
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="02_01_overview_of_llms.html">
            
                <a href="02_01_overview_of_llms.html">
            
                    
                    Overview of Large Language Models (LLMs)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="02_02_model_variations.html">
            
                <a href="02_02_model_variations.html">
            
                    
                    Models Variations
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="02_03_model_naming_conventions.html">
            
                <a href="02_03_model_naming_conventions.html">
            
                    
                    Model Naming Conventions
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="02_04_parameter_size.html">
            
                <a href="02_04_parameter_size.html">
            
                    
                    Parameter Size
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="02_05_quantization.html">
            
                <a href="02_05_quantization.html">
            
                    
                    Quantization
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.3.6" data-path="02_06_quantization_schemes.html">
            
                <a href="02_06_quantization_schemes.html">
            
                    
                    Quantization Schemes
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.7" data-path="02_07_scaling_models.html">
            
                <a href="02_07_scaling_models.html">
            
                    
                    How Models Are Scaled
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" >
            
                <span>
            
                    
                    Selecting Models
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="../03_selecting_models/03_01_selecting_the right model.html">
            
                <a href="../03_selecting_models/03_01_selecting_the right model.html">
            
                    
                    Selecting the Right Model
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="../03_selecting_models/03_02_pick_the_right_model_for_your_memory.html">
            
                <a href="../03_selecting_models/03_02_pick_the_right_model_for_your_memory.html">
            
                    
                    Pick the Right Model for Your Memory
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3" data-path="../03_selecting_models/03_03_model_size_and_memory.html">
            
                <a href="../03_selecting_models/03_03_model_size_and_memory.html">
            
                    
                    Model Size and Memory
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.4" data-path="../03_selecting_models/03_04_cpu_vs_gpu_inferencing.html">
            
                <a href="../03_selecting_models/03_04_cpu_vs_gpu_inferencing.html">
            
                    
                    CPU vs. GPU and Inferencing
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5" data-path="../03_selecting_models/03_05_offloading_to_the_gpu.html">
            
                <a href="../03_selecting_models/03_05_offloading_to_the_gpu.html">
            
                    
                    Offloading to the GPU
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.6" data-path="../03_selecting_models/03_06_picking_code_llama_instruct_variations.html">
            
                <a href="../03_selecting_models/03_06_picking_code_llama_instruct_variations.html">
            
                    
                    CodeLlama 3.1 Instruct Variations
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" >
            
                <span>
            
                    
                    Models For Coding
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../04_models_for_ coding/04_01_overview_of_code_llama_variations.html">
            
                <a href="../04_models_for_ coding/04_01_overview_of_code_llama_variations.html">
            
                    
                    Overview of Code Llama Variations
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2" data-path="../04_models_for_ coding/04_02_other_open_source_coding_models.html">
            
                <a href="../04_models_for_ coding/04_02_other_open_source_coding_models.html">
            
                    
                    Other Notable Open Source Models for Coding
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" >
            
                <span>
            
                    
                    Installation
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1" data-path="../05_installation/05_01_installing_lm_studio.html">
            
                <a href="../05_installation/05_01_installing_lm_studio.html">
            
                    
                    Installing LM Studio
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2" data-path="../05_installation/05_02_configuring_lm_studio_on_apple_silicon.html">
            
                <a href="../05_installation/05_02_configuring_lm_studio_on_apple_silicon.html">
            
                    
                    Configuring LM Studio on Apple Silicon
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.3" data-path="../05_installation/05_03_optimizing_lm_studio_for_apple_silicon.html">
            
                <a href="../05_installation/05_03_optimizing_lm_studio_for_apple_silicon.html">
            
                    
                    Optimizing LM Studio for Apple Silicon
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4" data-path="../05_installation/05_04_picking_models_in_lm_studio.html">
            
                <a href="../05_installation/05_04_picking_models_in_lm_studio.html">
            
                    
                    Picking Models in LM Studio
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.7" >
            
                <span>
            
                    
                    Evaluation
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.7.1" data-path="../06_evaluation/06_01_testing_each_model.html">
            
                <a href="../06_evaluation/06_01_testing_each_model.html">
            
                    
                    Testing Each Model
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.2" data-path="../06_evaluation/06_02_evaluating_models.html">
            
                <a href="../06_evaluation/06_02_evaluating_models.html">
            
                    
                    Evaluating Models with a Standardized Test
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.8" >
            
                <span>
            
                    
                    Best Practices
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.8.1" data-path="../07_best_practices/07_01_best_practices_for_running_local_llms.html">
            
                <a href="../07_best_practices/07_01_best_practices_for_running_local_llms.html">
            
                    
                    Best Practices for Running Local LLMs
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.9" >
            
                <span>
            
                    
                    Prompts
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.9.1" data-path="../08_prompts/08_01_collection_of_prompts.html">
            
                <a href="../08_prompts/08_01_collection_of_prompts.html">
            
                    
                    Collection of Prompts
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.2" data-path="../08_prompts/08_02_example_create_shell_script.html">
            
                <a href="../08_prompts/08_02_example_create_shell_script.html">
            
                    
                    Creating a Shell Script
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.10" >
            
                <span>
            
                    
                    Advanced Usage
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.10.1" data-path="../09_advanced_usage/09_01_advanced_model_tuning.html">
            
                <a href="../09_advanced_usage/09_01_advanced_model_tuning.html">
            
                    
                    Advanced Model Tuning
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.2" data-path="../09_advanced_usage/09_02_integrating_llms_into_workflows.html">
            
                <a href="../09_advanced_usage/09_02_integrating_llms_into_workflows.html">
            
                    
                    Integrating LLMs into Workflows
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.3" data-path="../09_advanced_usage/09_03_custom_built_pcs.html">
            
                <a href="../09_advanced_usage/09_03_custom_built_pcs.html">
            
                    
                    Custom Built PCs
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.11" >
            
                <span>
            
                    
                    Benchmarks
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.11.1" data-path="../10_benchmarks/10_01_geekbench_ai_benchmark.html">
            
                <a href="../10_benchmarks/10_01_geekbench_ai_benchmark.html">
            
                    
                    Personal Computer Results
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.2" data-path="../10_benchmarks/10_02_ryzen_7_5800_32.html">
            
                <a href="../10_benchmarks/10_02_ryzen_7_5800_32.html">
            
                    
                    Ryzen 7 5800X + RTX 4070 Super Performance Overview
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.3" data-path="../10_benchmarks/10_03_m3_max.html">
            
                <a href="../10_benchmarks/10_03_m3_max.html">
            
                    
                    MacBook Pro M3 Max Performance Overview
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.4" data-path="../10_benchmarks/10_04_nuc9v7qnx.html">
            
                <a href="../10_benchmarks/10_04_nuc9v7qnx.html">
            
                    
                    Intel NUC9V7QNX Performance Overview
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.12" >
            
                <span>
            
                    
                    Additional Resources
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.12.1" data-path="../11_additional_resources/11_01_tools.html">
            
                <a href="../11_additional_resources/11_01_tools.html">
            
                    
                    Tools
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.2" data-path="../11_additional_resources/11_02_articles.html">
            
                <a href="../11_additional_resources/11_02_articles.html">
            
                    
                    Articles
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.3" data-path="../11_additional_resources/11_03_in_the_news.html">
            
                <a href="../11_additional_resources/11_03_in_the_news.html">
            
                    
                    In the News
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://github.com/honkit/honkit" target="blank" class="gitbook-link">
            Published with HonKit
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Quantization Schemes</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="quantization-schemes">Quantization Schemes</h1>
<p>Quantization refers to the process of converting a model's parameters from higher precision (e.g., 32-bit floating point) to lower precision (e.g., 8-bit integer). This reduction in precision can significantly reduce the model's size and the computational resources required for inference, making it feasible to run larger models on less powerful hardware.</p>
<p>Quantization is a crucial technique for optimizing Large Language Models (LLMs) for local use, and understanding quantization schemes is essential for developers looking to maximize performance while minimizing resource usage. Quantization involves reducing the precision of the model parameters, which decreases model size and improves inference speed. Here’s a detailed breakdown of different quantization schemes, their implications, and how they can be applied effectively in environments like LM Studio.</p>
<h2 id="benefits-of-quantization">Benefits of Quantization</h2>
<ol>
<li><strong>Reduced Model Size</strong>: Quantized models are smaller, making them easier to store and load.</li>
<li><strong>Faster Inference</strong>: Lower precision calculations require fewer computational resources, resulting in faster inference times.</li>
<li><strong>Lower Power Consumption</strong>: Reduced computational load translates to lower power consumption, which is beneficial for battery-powered devices and energy-efficient applications.</li>
<li><strong>Resource Efficiency</strong>: Allows the deployment of complex models on hardware with limited resources, such as laptops or edge computing devices.</li>
</ol>
<h2 id="types-of-quantization">Types of Quantization</h2>
<p>Quantization can be broadly categorized into several types, each with its own advantages and trade-offs:</p>
<ol>
<li><strong>Post-Training Quantization (PTQ)</strong>: This method quantizes a pre-trained model without retraining. It's straightforward but might lead to a slight reduction in accuracy.</li>
<li><strong>Quantization-Aware Training (QAT)</strong>: This approach incorporates quantization into the training process. Models trained with QAT typically retain higher accuracy compared to PTQ.</li>
<li><strong>Dynamic Quantization</strong>: Only activations are quantized during inference, leaving weights at full precision. This method is less effective in reducing model size but can still speed up inference.</li>
<li><strong>Static Quantization</strong>: Both weights and activations are quantized, providing the greatest benefits in terms of model size and inference speed reduction.</li>
</ol>
<h2 id="quantization-schemes">Quantization Schemes</h2>
<p>Quantization schemes refer to the specific strategies used to apply quantization. They determine how the quantization process is implemented and optimized for different use cases.</p>
<ol>
<li><p><strong>Symmetric Quantization</strong>:</p>
<ul>
<li><strong>Description</strong>: Uses the same scale factor for positive and negative values. Simpler and more efficient for hardware implementations.</li>
<li><strong>Pros</strong>: Easier to implement, faster inference.</li>
<li><strong>Cons</strong>: May lead to reduced accuracy for models with a wide range of parameter values.</li>
</ul>
</li>
<li><p><strong>Asymmetric Quantization</strong>:</p>
<ul>
<li><strong>Description</strong>: Uses different scale factors for positive and negative values, allowing for a more accurate representation of the original model.</li>
<li><strong>Pros</strong>: Higher accuracy compared to symmetric quantization.</li>
<li><strong>Cons</strong>: More complex to implement and may have slightly higher computational overhead.</li>
</ul>
</li>
<li><p><strong>Per-Tensor Quantization</strong>:</p>
<ul>
<li><strong>Description</strong>: Applies a single scale factor to all elements of a tensor.</li>
<li><strong>Pros</strong>: Simpler and faster, good for general use.</li>
<li><strong>Cons</strong>: Less precise for tensors with a wide range of values.</li>
</ul>
</li>
<li><p><strong>Per-Channel Quantization</strong>:</p>
<ul>
<li><strong>Description</strong>: Applies different scale factors to each channel of a tensor.</li>
<li><strong>Pros</strong>: Higher precision, better for models with varying value ranges across channels.</li>
<li><strong>Cons</strong>: More complex and slower compared to per-tensor quantization.</li>
</ul>
</li>
</ol>
<h2 id="understanding-iq-models">Understanding "IQ" Models</h2>
<p>In addition to standard quantization schemes, you may encounter models labeled with "IQ" (Intelligent Quantization) prefixes, such as IQ1 or IQ2. These IQ models take the concept of quantization further by applying advanced optimization techniques during or after the quantization process.</p>
<ul>
<li><strong>Enhanced Performance</strong>: IQ models are designed to retain more of the original model's accuracy and performance, despite the reduced precision. They are particularly beneficial when you need to maintain high performance on tasks that require nuanced understanding, without the full computational overhead of a non-quantized model.</li>
<li><strong>Optimized Resource Usage</strong>: While IQ models may have similar memory footprints to their standard quantized counterparts, they are typically more efficient in handling inferencing tasks. This efficiency can lead to faster processing times and better overall system performance, especially on hardware with limited resources.</li>
<li><strong>When to Use IQ Models</strong>: Opt for IQ models if you’re looking to strike the best balance between resource efficiency and model accuracy. They are especially useful in scenarios where precision is critical, such as in detailed coding tasks or complex language understanding.</li>
</ul>
<h2 id="optimizing-quantization-schemes">Optimizing Quantization Schemes</h2>
<p>To optimize quantization schemes for your LLMs in an environment like LM Studio, consider the following steps:</p>
<ol>
<li><strong>Evaluate Model Requirements</strong>: Determine the acceptable trade-offs between model size, inference speed, and accuracy.</li>
<li><strong>Choose the Appropriate Scheme</strong>: Select a quantization scheme that aligns with your performance and resource requirements.</li>
<li><strong>Implement and Test in LM Studio</strong>: Apply the chosen quantization scheme within LM Studio and rigorously test the model to ensure it meets your accuracy and performance benchmarks.</li>
<li><strong>Iterate and Refine</strong>: Based on testing results, adjust the quantization parameters and re-evaluate to achieve the best balance between performance and resource usage.</li>
</ol>
<p>Understanding and implementing the right quantization scheme is crucial for optimizing LLMs for local use. By carefully selecting and applying quantization strategies, developers can significantly reduce model size, improve inference speed, and make sophisticated AI models accessible on a broader range of hardware. This enables efficient, high-performance coding assistance tailored to the specific needs and constraints of your development environment.</p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="02_05_quantization.html" class="navigation navigation-prev " aria-label="Previous page: Quantization">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="02_07_scaling_models.html" class="navigation navigation-next " aria-label="Next page: How Models Are Scaled">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Quantization Schemes","level":"1.3.6","depth":2,"next":{"title":"How Models Are Scaled","level":"1.3.7","depth":2,"path":"02_understanding_large_language_models/02_07_scaling_models.md","ref":"./02_understanding_large_language_models/02_07_scaling_models.md","articles":[]},"previous":{"title":"Quantization","level":"1.3.5","depth":2,"path":"02_understanding_large_language_models/02_05_quantization.md","ref":"./02_understanding_large_language_models/02_05_quantization.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":[],"pluginsConfig":{"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56},"embedFonts":false},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"02_understanding_large_language_models/02_06_quantization_schemes.md","mtime":"2024-08-27T18:31:41.762Z","type":"markdown"},"gitbook":{"version":"5.1.4","time":"2024-08-27T18:50:45.127Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <noscript>
        <style>
            .honkit-cloak {
                display: block !important;
            }
        </style>
    </noscript>
    <script>
        // Restore sidebar state as critical path for prevent layout shift
        function __init__getSidebarState(defaultValue){
            var baseKey = "";
            var key = baseKey + ":sidebar";
            try {
                var value = localStorage[key];
                if (value === undefined) {
                    return defaultValue;
                }
                var parsed = JSON.parse(value);
                return parsed == null ? defaultValue : parsed;
            } catch (e) {
                return defaultValue;
            }
        }
        function __init__restoreLastSidebarState() {
            var isMobile = window.matchMedia("(max-width: 600px)").matches;
            if (isMobile) {
                // Init last state if not mobile
                return;
            }
            var sidebarState = __init__getSidebarState(true);
            var book = document.querySelector(".book");
            // Show sidebar if it enabled
            if (sidebarState && book) {
                book.classList.add("without-animation", "with-summary");
            }
        }

        try {
            __init__restoreLastSidebarState();
        } finally {
            var book = document.querySelector(".book");
            book.classList.remove("honkit-cloak");
        }
    </script>
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

