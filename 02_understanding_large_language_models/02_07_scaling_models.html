
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <title>How Models Are Scaled · HonKit</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="HonKit 5.1.4">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/@honkit/honkit-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    
    <link rel="prev" href="02_06_quantization_schemes.html" />
    

    </head>
    <body>
        
<div class="book honkit-cloak">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" >
            
                <span>
            
                    
                    Introduction
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="../01_introduction/01_01_how_to_use_this_guide.html">
            
                <a href="../01_introduction/01_01_how_to_use_this_guide.html">
            
                    
                    How To Use This Guide
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="../01_introduction/01_02_why_run_models_locally.html">
            
                <a href="../01_introduction/01_02_why_run_models_locally.html">
            
                    
                    Why Run Large Language Models Locally?
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" >
            
                <span>
            
                    
                    Understanding Large Language Models
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="02_01_overview_of_llms.html">
            
                <a href="02_01_overview_of_llms.html">
            
                    
                    Overview of Large Language Models (LLMs)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="02_02_model_variations.html">
            
                <a href="02_02_model_variations.html">
            
                    
                    Models Variations
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="02_03_model_naming_conventions.html">
            
                <a href="02_03_model_naming_conventions.html">
            
                    
                    Model Naming Conventions
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="02_04_parameter_size.html">
            
                <a href="02_04_parameter_size.html">
            
                    
                    Parameter Size
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="02_05_quantization.html">
            
                <a href="02_05_quantization.html">
            
                    
                    Quantization
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.6" data-path="02_06_quantization_schemes.html">
            
                <a href="02_06_quantization_schemes.html">
            
                    
                    Quantization Schemes
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.3.7" data-path="02_07_scaling_models.html">
            
                <a href="02_07_scaling_models.html">
            
                    
                    How Models Are Scaled
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" >
            
                <span>
            
                    
                    Selecting Models
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="../03_selecting_models/03_01_selecting_the right model.html">
            
                <a href="../03_selecting_models/03_01_selecting_the right model.html">
            
                    
                    Selecting the Right Model
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="../03_selecting_models/03_02_pick_the_right_model_for_your_memory.html">
            
                <a href="../03_selecting_models/03_02_pick_the_right_model_for_your_memory.html">
            
                    
                    Pick the Right Model for Your Memory
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3" data-path="../03_selecting_models/03_03_model_size_and_memory.html">
            
                <a href="../03_selecting_models/03_03_model_size_and_memory.html">
            
                    
                    Model Size and Memory
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.4" data-path="../03_selecting_models/03_04_cpu_vs_gpu_inferencing.html">
            
                <a href="../03_selecting_models/03_04_cpu_vs_gpu_inferencing.html">
            
                    
                    CPU vs. GPU and Inferencing
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5" data-path="../03_selecting_models/03_05_offloading_to_the_gpu.html">
            
                <a href="../03_selecting_models/03_05_offloading_to_the_gpu.html">
            
                    
                    Offloading to the GPU
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.6" data-path="../03_selecting_models/03_06_picking_code_llama_instruct_variations.html">
            
                <a href="../03_selecting_models/03_06_picking_code_llama_instruct_variations.html">
            
                    
                    CodeLlama 3.1 Instruct Variations
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" >
            
                <span>
            
                    
                    Models For Coding
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../04_models_for_ coding/04_01_overview_of_code_llama_variations.html">
            
                <a href="../04_models_for_ coding/04_01_overview_of_code_llama_variations.html">
            
                    
                    Overview of Code Llama Variations
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2" data-path="../04_models_for_ coding/04_02_other_open_source_coding_models.html">
            
                <a href="../04_models_for_ coding/04_02_other_open_source_coding_models.html">
            
                    
                    Other Notable Open Source Models for Coding
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" >
            
                <span>
            
                    
                    Installation
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1" data-path="../05_installation/05_01_installing_lm_studio.html">
            
                <a href="../05_installation/05_01_installing_lm_studio.html">
            
                    
                    Installing LM Studio
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2" data-path="../05_installation/05_02_configuring_lm_studio_on_apple_silicon.html">
            
                <a href="../05_installation/05_02_configuring_lm_studio_on_apple_silicon.html">
            
                    
                    Configuring LM Studio on Apple Silicon
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.3" data-path="../05_installation/05_03_optimizing_lm_studio_for_apple_silicon.html">
            
                <a href="../05_installation/05_03_optimizing_lm_studio_for_apple_silicon.html">
            
                    
                    Optimizing LM Studio for Apple Silicon
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4" data-path="../05_installation/05_04_picking_models_in_lm_studio.html">
            
                <a href="../05_installation/05_04_picking_models_in_lm_studio.html">
            
                    
                    Picking Models in LM Studio
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.7" >
            
                <span>
            
                    
                    Evaluation
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.7.1" data-path="../06_evaluation/06_01_testing_each_model.html">
            
                <a href="../06_evaluation/06_01_testing_each_model.html">
            
                    
                    Testing Each Model
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.2" data-path="../06_evaluation/06_02_evaluating_models.html">
            
                <a href="../06_evaluation/06_02_evaluating_models.html">
            
                    
                    Evaluating Models with a Standardized Test
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.8" >
            
                <span>
            
                    
                    Best Practices
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.8.1" data-path="../07_best_practices/07_01_best_practices_for_running_local_llms.html">
            
                <a href="../07_best_practices/07_01_best_practices_for_running_local_llms.html">
            
                    
                    Best Practices for Running Local LLMs
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.9" >
            
                <span>
            
                    
                    Prompts
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.9.1" data-path="../08_prompts/08_01_collection_of_prompts.html">
            
                <a href="../08_prompts/08_01_collection_of_prompts.html">
            
                    
                    Collection of Prompts
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.2" data-path="../08_prompts/08_02_example_create_shell_script.html">
            
                <a href="../08_prompts/08_02_example_create_shell_script.html">
            
                    
                    Creating a Shell Script
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.10" >
            
                <span>
            
                    
                    Advanced Usage
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.10.1" data-path="../09_advanced_usage/09_01_advanced_model_tuning.html">
            
                <a href="../09_advanced_usage/09_01_advanced_model_tuning.html">
            
                    
                    Advanced Model Tuning
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.2" data-path="../09_advanced_usage/09_02_integrating_llms_into_workflows.html">
            
                <a href="../09_advanced_usage/09_02_integrating_llms_into_workflows.html">
            
                    
                    Integrating LLMs into Workflows
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.3" data-path="../09_advanced_usage/09_03_custom_built_pcs.html">
            
                <a href="../09_advanced_usage/09_03_custom_built_pcs.html">
            
                    
                    Custom Built PCs
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.11" >
            
                <span>
            
                    
                    Benchmarks
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.11.1" data-path="../10_benchmarks/10_01_geekbench_ai_benchmark.html">
            
                <a href="../10_benchmarks/10_01_geekbench_ai_benchmark.html">
            
                    
                    Personal Computer Results
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.2" data-path="../10_benchmarks/10_02_ryzen_7_5800_32.html">
            
                <a href="../10_benchmarks/10_02_ryzen_7_5800_32.html">
            
                    
                    Ryzen 7 5800X + RTX 4070 Super Performance Overview
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.3" data-path="../10_benchmarks/10_03_m3_max.html">
            
                <a href="../10_benchmarks/10_03_m3_max.html">
            
                    
                    MacBook Pro M3 Max Performance Overview
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.4" data-path="../10_benchmarks/10_04_nuc9v7qnx.html">
            
                <a href="../10_benchmarks/10_04_nuc9v7qnx.html">
            
                    
                    Intel NUC9V7QNX Performance Overview
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.12" >
            
                <span>
            
                    
                    Additional Resources
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.12.1" data-path="../11_additional_resources/11_01_tools.html">
            
                <a href="../11_additional_resources/11_01_tools.html">
            
                    
                    Tools
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.2" data-path="../11_additional_resources/11_02_articles.html">
            
                <a href="../11_additional_resources/11_02_articles.html">
            
                    
                    Articles
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.3" data-path="../11_additional_resources/11_03_in_the_news.html">
            
                <a href="../11_additional_resources/11_03_in_the_news.html">
            
                    
                    In the News
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://github.com/honkit/honkit" target="blank" class="gitbook-link">
            Published with HonKit
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >How Models Are Scaled</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="how-models-are-scaled">How Models Are Scaled</h1>
<p>Scaling up a model, such as going from an 8B (8 billion parameters) model to a 13B, 34B, or even larger, involves a significant increase in the model’s complexity and capacity. This process is crucial for developing models that can handle more intricate tasks, provide greater accuracy, and generate more sophisticated outputs. Here’s how this scaling process works:</p>
<h2 id="what-does-it-mean-to-scale-a-model">What Does It Mean to Scale a Model?</h2>
<p>Scaling a model means increasing the number of parameters—the weights and biases within the neural network—that the model uses to make predictions. These parameters are the core components of any machine learning model, determining how well it can learn from data and make accurate predictions or generate outputs.</p>
<p>In simple terms, the more parameters a model has, the "bigger" it is. A larger model can capture more complex patterns in data, allowing it to perform better on more challenging tasks. However, this also comes with increased computational requirements, both for training and inferencing.</p>
<h2 id="steps-to-make-a-model-bigger">Steps to Make a Model Bigger</h2>
<ol>
<li><p><strong>Increase the Number of Layers</strong>:</p>
<ul>
<li><strong>Layer Expansion</strong>: One of the primary methods to scale up a model is by adding more layers to the neural network. Each layer in a neural network consists of neurons that process inputs and pass on their outputs to the next layer. By increasing the number of layers, the model can learn more abstract features of the data at deeper levels.</li>
<li><strong>Deeper Networks</strong>: As you add more layers, the network becomes "deeper." Deeper networks are capable of learning more intricate patterns and representations, which is why they are often more accurate for complex tasks.</li>
</ul>
</li>
<li><p><strong>Widen the Layers</strong>:</p>
<ul>
<li><strong>Increasing Neurons per Layer</strong>: Another approach to scaling is to increase the number of neurons (units) within each layer. This means that each layer can process more information at once, allowing the model to capture a broader range of features from the input data.</li>
<li><strong>Wider Networks</strong>: Widening layers results in a "wider" network, which can improve the model’s ability to generalize from the training data, especially when dealing with large and diverse datasets.</li>
</ul>
</li>
<li><p><strong>Expanding the Embedding Size</strong>:</p>
<ul>
<li><strong>Larger Embeddings</strong>: In language models, the embedding layer converts words or tokens into numerical vectors that represent their meanings in a multi-dimensional space. By increasing the embedding size, the model can capture more nuanced meanings and relationships between words, leading to better performance on tasks involving language understanding and generation.</li>
<li><strong>Enhanced Representations</strong>: Larger embeddings allow the model to represent more complex relationships within the data, which is particularly important for tasks requiring high levels of comprehension or creativity.</li>
</ul>
</li>
<li><p><strong>Training with More Data</strong>:</p>
<ul>
<li><strong>Data Requirements</strong>: As models grow in size, they require more data to train effectively. This ensures that the additional parameters do not lead to overfitting (where the model performs well on training data but poorly on unseen data). Training on larger and more diverse datasets helps the model generalize better, taking full advantage of the increased capacity.</li>
<li><strong>Longer Training Times</strong>: Scaling a model not only requires more data but also significantly increases training times. Larger models take longer to train because they need to process more data and adjust a greater number of parameters.</li>
</ul>
</li>
<li><p><strong>Fine-Tuning and Specialization</strong>:</p>
<ul>
<li><strong>Targeted Training</strong>: Once a larger model is trained, it can be fine-tuned on specific tasks or datasets. Fine-tuning allows the model to adapt its vast capacity to particular domains, improving its performance in areas like natural language understanding, code generation, or image recognition.</li>
<li><strong>Specialized Models</strong>: For instance, fine-tuning a 13B model on instruction-based datasets might produce an "Instruct" variant of the model that is optimized for following and generating detailed instructions.</li>
</ul>
</li>
<li><p><strong>Quantization and Optimization</strong>:</p>
<ul>
<li><strong>Memory Efficiency</strong>: As models become larger, they require more memory to run effectively. To address this, techniques like quantization are used, where the precision of the model’s parameters is reduced (e.g., from 32-bit to 16-bit or 8-bit). This reduces the model’s memory footprint, making it more feasible to deploy on consumer hardware without sacrificing too much performance.</li>
<li><strong>Inference Speed</strong>: Quantization also speeds up inference times because the model uses less computational power to process the reduced-precision parameters, which is particularly beneficial for deploying large models on GPUs with limited VRAM.</li>
</ul>
</li>
</ol>
<h2 id="challenges-of-scaling-models">Challenges of Scaling Models</h2>
<p>While scaling up a model provides greater capacity and performance, it also comes with challenges:</p>
<ul>
<li><strong>Increased Computational Costs</strong>: Larger models require more powerful hardware, including more RAM and VRAM, and longer training times, which can be costly.</li>
<li><strong>Resource Management</strong>: Managing the resources to train and deploy larger models effectively requires careful planning, especially when dealing with extremely large models like those with tens or hundreds of billions of parameters.</li>
<li><strong>Risk of Overfitting</strong>: Without sufficient training data, larger models may overfit, meaning they learn the training data too well but fail to generalize to new inputs. This risk necessitates the use of vast and diverse datasets.</li>
</ul>
<h4 id="conclusion">Conclusion</h4>
<p>Scaling models is a crucial process in the development of advanced LLMs, allowing them to handle more complex tasks and deliver more accurate outputs. By understanding the methods and challenges involved in making a model bigger, developers and researchers can better utilize these powerful tools to push the boundaries of what AI can achieve.</p>
<hr></hr>
<p>This section should provide a comprehensive overview of how models are scaled up and what that entails. Let me know if this fits well into your guide or if there’s anything else you’d like to adjust!</p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="02_06_quantization_schemes.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page: Quantization Schemes">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"How Models Are Scaled","level":"1.3.7","depth":2,"next":{"title":"Selecting Models","level":"1.4","depth":1,"ref":"","articles":[{"title":"Selecting the Right Model","level":"1.4.1","depth":2,"path":"03_selecting_models/03_01_selecting_the right model.md","ref":"./03_selecting_models/03_01_selecting_the right model.md","articles":[]},{"title":"Pick the Right Model for Your Memory","level":"1.4.2","depth":2,"path":"03_selecting_models/03_02_pick_the_right_model_for_your_memory.md","ref":"./03_selecting_models/03_02_pick_the_right_model_for_your_memory.md","articles":[]},{"title":"Model Size and Memory","level":"1.4.3","depth":2,"path":"03_selecting_models/03_03_model_size_and_memory.md","ref":"./03_selecting_models/03_03_model_size_and_memory.md","articles":[]},{"title":"CPU vs. GPU and Inferencing","level":"1.4.4","depth":2,"path":"03_selecting_models/03_04_cpu_vs_gpu_inferencing.md","ref":"./03_selecting_models/03_04_cpu_vs_gpu_inferencing.md","articles":[]},{"title":"Offloading to the GPU","level":"1.4.5","depth":2,"path":"03_selecting_models/03_05_offloading_to_the_gpu.md","ref":"./03_selecting_models/03_05_offloading_to_the_gpu.md","articles":[]},{"title":"CodeLlama 3.1 Instruct Variations","level":"1.4.6","depth":2,"path":"03_selecting_models/03_06_picking_code_llama_instruct_variations.md","ref":"./03_selecting_models/03_06_picking_code_llama_instruct_variations.md","articles":[]}]},"previous":{"title":"Quantization Schemes","level":"1.3.6","depth":2,"path":"02_understanding_large_language_models/02_06_quantization_schemes.md","ref":"./02_understanding_large_language_models/02_06_quantization_schemes.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":[],"pluginsConfig":{"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56},"embedFonts":false},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"02_understanding_large_language_models/02_07_scaling_models.md","mtime":"2024-08-27T18:31:41.762Z","type":"markdown"},"gitbook":{"version":"5.1.4","time":"2024-08-27T18:50:45.127Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <noscript>
        <style>
            .honkit-cloak {
                display: block !important;
            }
        </style>
    </noscript>
    <script>
        // Restore sidebar state as critical path for prevent layout shift
        function __init__getSidebarState(defaultValue){
            var baseKey = "";
            var key = baseKey + ":sidebar";
            try {
                var value = localStorage[key];
                if (value === undefined) {
                    return defaultValue;
                }
                var parsed = JSON.parse(value);
                return parsed == null ? defaultValue : parsed;
            } catch (e) {
                return defaultValue;
            }
        }
        function __init__restoreLastSidebarState() {
            var isMobile = window.matchMedia("(max-width: 600px)").matches;
            if (isMobile) {
                // Init last state if not mobile
                return;
            }
            var sidebarState = __init__getSidebarState(true);
            var book = document.querySelector(".book");
            // Show sidebar if it enabled
            if (sidebarState && book) {
                book.classList.add("without-animation", "with-summary");
            }
        }

        try {
            __init__restoreLastSidebarState();
        } finally {
            var book = document.querySelector(".book");
            book.classList.remove("honkit-cloak");
        }
    </script>
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

